{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM0UJD7W5Y79"
      },
      "source": [
        "# CS 4770 Natural Language Processing (Fall 2025)\n",
        "\n",
        "## Assignment 1: PyTorch Warm-Up\n",
        "\n",
        "In this assignment, you will use PyTorch to implement and train a simple neural network on SST-2 dataset. This assignment will help you get familiar with the PyTorch library and the basic concepts of neural networks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5lc89tY5LNf",
        "outputId": "7f5e9ae9-7d0b-44dc-d70b-65f8600a40c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x210ba764590>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Set random seeds\n",
        "np.random.seed(99)\n",
        "torch.manual_seed(99)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUga99_O5zEZ"
      },
      "source": [
        "## Question 1: Python Lists and NumPy Arrays (5 pts).\n",
        "\n",
        "TODO: Create a Python list of the first 12 cube numbers $(1, 8, 27, â€¦, 1728)$.\n",
        "\n",
        "Convert this list to a NumPy array and reshape it into a $3\\times4$ matrix. Print out the matrix as a 2-dimensional array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rIf9qUWezNdm"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[   1,    8,   27,   64],\n",
              "       [ 125,  216,  343,  512],\n",
              "       [ 729, 1000, 1331, 1728]])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cube = [i ** 3 for i in range(1, 13)]\n",
        "cube_arr = np.array(cube).reshape((3, 4))\n",
        "cube_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCYQQGs96MSn"
      },
      "source": [
        "## Question 2: PyTorch Tensors and Operations (11 pts)\n",
        "\n",
        "Convert the NumPy array from Question 1 into a PyTorch float32 tensor and perform the following operations. The following operations must be done using PyTorch interfaces.\n",
        "\n",
        "TODO: Subtract 5 from every element and print out the mean of all elements. (5 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Om74uiYL6hiR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of all elements: 502.0\n"
          ]
        }
      ],
      "source": [
        "cube_tensor = torch.tensor(cube_arr, dtype=torch.float32)\n",
        "cube_broadcasted = cube_tensor - 5\n",
        "print(f\"Mean of all elements: {torch.mean(cube_broadcasted).item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ic-Dw4Um4_Db"
      },
      "source": [
        "TODO: Create a new $4 \\times 3$ tensor by transposing the original tensor. Print out the transposed tensor. (3 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "GBmy3kiq4-kc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1.0000e+00, 1.2500e+02, 7.2900e+02],\n",
              "        [8.0000e+00, 2.1600e+02, 1.0000e+03],\n",
              "        [2.7000e+01, 3.4300e+02, 1.3310e+03],\n",
              "        [6.4000e+01, 5.1200e+02, 1.7280e+03]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cube_T = cube_tensor.T\n",
        "cube_T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_lpD-8C5FCX"
      },
      "source": [
        "TODO: Perform matrix multiplication between the original tensor and the transposed tensor. Print out the result. (3 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "INGdzlA95GxT"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[4.8900e+03, 4.3882e+04, 1.5526e+05],\n",
              "        [4.3882e+04, 4.4207e+05, 1.6484e+06],\n",
              "        [1.5526e+05, 1.6484e+06, 6.2890e+06]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cube_mult = cube_tensor @ cube_T\n",
        "cube_mult"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra8MwUOZ6rwo"
      },
      "source": [
        "## Question 3: SST-2 Sentiment Classification (30 pts)\n",
        "\n",
        "In this question, you will build a simple neural network to predict whether a sentence expresses positive or negative sentiment. We will use the SST-2 (Stanford Sentiment Treebank, Binary version) dataset. This dataset is widely used in NLP research and is available through the HuggingFace datasets library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4-BqZRF8bvN"
      },
      "source": [
        "Install HuggingFace datasets library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-w2u7Oc7lmc"
      },
      "outputs": [],
      "source": [
        "# Installed via uv instead\n",
        "# !pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUlOwwFG8htm"
      },
      "source": [
        "Load and preprocess the dataset. (You don't need to modify this cell.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xU6zwfeJ8jBi"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\User\\Projects\\UVA\\NLP\\Assigments\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 67349, \n",
            "Val size: 872, \n",
            "Test size: 872\n",
            "Sentence:  hide new secretions from the parental units \n",
            "Sentiment:  Negative\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from datasets import load_dataset\n",
        "\n",
        "np.random.seed(99)\n",
        "torch.manual_seed(99)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Function that preprocesses the string\n",
        "    \"\"\"\n",
        "    preprocessed_text = text.lower()\n",
        "    return preprocessed_text\n",
        "\n",
        "# Load SST-2 dataset from HuggingFace\n",
        "dataset = load_dataset(\"glue\", \"sst2\")\n",
        "\n",
        "# Extract train, validation and test sets\n",
        "train_data = dataset[\"train\"]\n",
        "val_data = dataset[\"validation\"]\n",
        "test_data = dataset[\"test\"]\n",
        "\n",
        "# Process training data\n",
        "train_contents = [preprocess_text(example[\"sentence\"]) for example in train_data]\n",
        "train_labels = [example[\"label\"] for example in train_data]\n",
        "\n",
        "# Process validation data\n",
        "val_contents = [preprocess_text(example[\"sentence\"]) for example in val_data]\n",
        "val_labels = [example[\"label\"] for example in val_data]\n",
        "\n",
        "# Process test data (note: SST-2 test set doesn't have labels, using validation as test)\n",
        "test_contents = [preprocess_text(example[\"sentence\"]) for example in val_data]\n",
        "test_labels = [example[\"label\"] for example in val_data]\n",
        "\n",
        "sentiments = [\"Negative\", \"Positive\"]\n",
        "\n",
        "print(f\"Train size: {len(train_contents)}, \"\n",
        "      f\"\\nVal size: {len(val_contents)}, \"\n",
        "      f\"\\nTest size: {len(test_contents)}\")\n",
        "\n",
        "# show the first review and its sentiment label\n",
        "print(\"Sentence: \", train_data[0][\"sentence\"])\n",
        "print(\"Sentiment: \", sentiments[train_labels[0]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUb0BWnO8sP_"
      },
      "source": [
        "Define the SST-2 dataset class. (You don't need to modify this cell.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CC6x0hDQ8uSW"
      },
      "outputs": [],
      "source": [
        "# Vectorize the text data using CountVectorizer\n",
        "vectorizer = CountVectorizer(max_features=10000)\n",
        "X_train = vectorizer.fit_transform(train_contents).toarray()\n",
        "X_val = vectorizer.transform(val_contents).toarray()\n",
        "X_test = vectorizer.transform(test_contents).toarray()\n",
        "\n",
        "y_train = np.array(train_labels)\n",
        "y_val = np.array(val_labels)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "class SST2Dataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.texts = torch.tensor(texts, dtype=torch.float32)\n",
        "        self.labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.texts[idx], self.labels[idx]\n",
        "\n",
        "# Create DataLoader objects\n",
        "train_dataset = SST2Dataset(X_train, y_train)\n",
        "val_dataset = SST2Dataset(X_val, y_val)\n",
        "test_dataset = SST2Dataset(X_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W33c3hjP6iG-"
      },
      "source": [
        "TODO: Implement a simple two-layer neural network using PyTorch's `nn.Module` for binary classification. The network should have:\n",
        "\n",
        "- An input layer of **input\\_dim** features.\n",
        "- One hidden layer with 64 neurons and **ReLU** activation.\n",
        "- An output layer with 1 neuron and **Sigmoid** activation.\n",
        "\n",
        "Then initialize the model where **input\\_dim** equals the shape of the data in **X\\_train**, use the Binary Entropy loss function, and the Adam optimizer with 0.001 learning rate. (10 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "aYlK1euG7Vc1"
      },
      "outputs": [],
      "source": [
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "       x = self.fc1(x)\n",
        "       x = torch.relu(x)\n",
        "       x = self.fc2(x)\n",
        "       return torch.sigmoid(x)\n",
        "\n",
        "# TODO: initialize the model, loss and optimizer\n",
        "input_dim = X_train.shape[1]\n",
        "model = SimpleNN(input_dim=input_dim)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLVErJk07XhF"
      },
      "source": [
        "TODO: Train the neural network for 10 epochs, and print out the training loss and accuracy on the training set at the end of each epoch. (10 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "stCPhyP-7baN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Train Loss: 0.3478, Train Acc: 0.8485, \n",
            "Epoch 2/10, Train Loss: 0.2039, Train Acc: 0.9163, \n",
            "Epoch 3/10, Train Loss: 0.1569, Train Acc: 0.9361, \n",
            "Epoch 4/10, Train Loss: 0.1264, Train Acc: 0.9482, \n",
            "Epoch 5/10, Train Loss: 0.1042, Train Acc: 0.9571, \n",
            "Epoch 6/10, Train Loss: 0.0866, Train Acc: 0.9642, \n",
            "Epoch 7/10, Train Loss: 0.0749, Train Acc: 0.9691, \n",
            "Epoch 8/10, Train Loss: 0.0650, Train Acc: 0.9723, \n",
            "Epoch 9/10, Train Loss: 0.0573, Train Acc: 0.9756, \n",
            "Epoch 10/10, Train Loss: 0.0517, Train Acc: 0.9773, \n"
          ]
        }
      ],
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # TODO: Complete the training loop, update the training loss and accuracy\n",
        "    for i, (texts, labels) in enumerate(train_loader):\n",
        "        # Forward prop\n",
        "        outputs = model(texts)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Back prop\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Metrics\n",
        "        train_loss += loss.item()\n",
        "        predictions = (outputs >= 0.5).float()\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total += labels.shape[0]\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_acc = correct / total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
        "          f\"Train Loss: {train_loss:.4f}, \"\n",
        "          f\"Train Acc: {train_acc:.4f}, \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGHG8jDY7cHl"
      },
      "source": [
        "TODO: Evaluate the test set and report the test accuracy. (10 pts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "_WZTc1f67fpW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8234\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "test_correct = 0\n",
        "with torch.no_grad():\n",
        "    for i, (texts, labels) in enumerate(test_loader):\n",
        "        # Forward prop\n",
        "        outputs = model(texts)\n",
        "\n",
        "        # Metrics\n",
        "        predictions = (outputs >= 0.5).float()\n",
        "        test_correct += (predictions == labels).sum().item()\n",
        "\n",
        "test_acc = test_correct / len(test_loader.dataset)\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "assigments",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
